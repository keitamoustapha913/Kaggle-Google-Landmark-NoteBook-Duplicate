{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:30:35.681372Z",
     "iopub.status.busy": "2020-09-29T10:30:35.670314Z",
     "iopub.status.idle": "2020-09-29T10:34:21.970308Z",
     "shell.execute_reply": "2020-09-29T10:34:21.970942Z"
    },
    "papermill": {
     "duration": 226.346124,
     "end_time": "2020-09-29T10:34:21.971218",
     "exception": false,
     "start_time": "2020-09-29T10:30:35.625094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages\n",
      "Found existing installation: allennlp 1.0.0\r\n",
      "Uninstalling allennlp-1.0.0:\r\n",
      "  Successfully uninstalled allennlp-1.0.0\r\n",
      "Found existing installation: torch 1.5.1\r\n",
      "Uninstalling torch-1.5.1:\r\n",
      "  Successfully uninstalled torch-1.5.1\r\n",
      "Processing /kaggle/input/torch16/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==1.6.0cu101) (0.18.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.6.0cu101) (1.18.5)\r\n",
      "Installing collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.5.1\r\n",
      "    Uninstalling torch-1.5.1:\r\n",
      "      Successfully uninstalled torch-1.5.1\r\n",
      "Successfully installed torch-1.6.0+cu101\r\n",
      "Processing /kaggle/input/pytorch-image-models\r\n",
      "Requirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm==0.2.1) (1.6.0+cu101)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.2.1) (0.6.0a0+35d732a)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.2.1) (1.18.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.2.1) (0.18.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.2.1) (7.2.0)\r\n",
      "Building wheels for collected packages: timm\r\n",
      "  Building wheel for timm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for timm: filename=timm-0.2.1-py3-none-any.whl size=228223 sha256=65a4cb99fd2c7e474a0ed6865c7653c914c81cd02d439fdccbdf99f7b8d32498\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6e/a1/9f/ba52506e62a11fa95ed7b1efbb42f9e84c2d5e7401469da686\r\n",
      "Successfully built timm\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.2.1\r\n",
      "Processing /kaggle/input/yacs-yet-another-configuration-system/yacs\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs==0.1.6) (5.3.1)\r\n",
      "Building wheels for collected packages: yacs\r\n",
      "  Building wheel for yacs (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for yacs: filename=yacs-0.1.6-py3-none-any.whl size=14497 sha256=e1fa190b6a2a9ff3ae9a0234a995321fd28a1b8e2246076dd719a79dcd5dfa8f\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7gja_kdf/wheels/20/98/bd/54211246fa0021d7d12db94b80df2650c4a06cbc3cf2445135\r\n",
      "Successfully built yacs\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.6\r\n",
      "Processing /kaggle/input/landmark-lib\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from cvcore==0.0.1) (1.6.0+cu101)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from cvcore==0.0.1) (0.6.0a0+35d732a)\r\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (from cvcore==0.0.1) (0.2.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->cvcore==0.0.1) (1.18.5)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->cvcore==0.0.1) (0.18.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->cvcore==0.0.1) (7.2.0)\r\n",
      "Building wheels for collected packages: cvcore\r\n",
      "  Building wheel for cvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for cvcore: filename=cvcore-0.0.1-py3-none-any.whl size=64446 sha256=f12c0b84f730aed5ef86810cebf7a28bcf438a8763992dfaa535cbdbcdb0f696\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/8c/07/708db4cd6a13f45cc87670bcb1d9922544c580a8251acc7b06\r\n",
      "Successfully built cvcore\r\n",
      "Installing collected packages: cvcore\r\n",
      "Successfully installed cvcore-0.0.1\r\n",
      "Processing /kaggle/input/semantic-segmentation-pytorch\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (1.18.5)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (1.6.0+cu101)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (0.6.0a0+35d732a)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (4.3.0.36)\r\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (0.1.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (1.4.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from mit-semseg==1.0.0) (4.45.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.1->mit-semseg==1.0.0) (0.18.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->mit-semseg==1.0.0) (7.2.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs->mit-semseg==1.0.0) (5.3.1)\r\n",
      "Building wheels for collected packages: mit-semseg\r\n",
      "  Building wheel for mit-semseg (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mit-semseg: filename=mit_semseg-1.0.0-py3-none-any.whl size=46925 sha256=55bc87d99732692cee23783d71f852f16b889884fcb9901867aff41f2b8e7b48\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/8e/61/1aef72f538f1495d1887f5e754ecbe9bf9afd9a7382e44f7ce\r\n",
      "Successfully built mit-semseg\r\n",
      "Installing collected packages: mit-semseg\r\n",
      "Successfully installed mit-semseg-1.0.0\r\n",
      "Processing /kaggle/input/superpoint-pytorch\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (1.6.0+cu101)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (0.6.0a0+35d732a)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (1.18.5)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (4.3.0.36)\r\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (0.1.6)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from superpoint-pytorch==0.0.1) (1.4.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->superpoint-pytorch==0.0.1) (0.18.2)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->superpoint-pytorch==0.0.1) (7.2.0)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs->superpoint-pytorch==0.0.1) (5.3.1)\r\n",
      "Building wheels for collected packages: superpoint-pytorch\r\n",
      "  Building wheel for superpoint-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for superpoint-pytorch: filename=superpoint_pytorch-0.0.1-py3-none-any.whl size=1297 sha256=c325a0c92c8121dcbc8622489bbccf9b30e268fe51427709472172643a3c6899\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/0e/56/45bfd307cf78c61b1fb873b7c461a445c610ad259dd88f8c1b\r\n",
      "Successfully built superpoint-pytorch\r\n",
      "Installing collected packages: superpoint-pytorch\r\n",
      "Successfully installed superpoint-pytorch-0.0.1\r\n",
      "Installed packages\n"
     ]
    }
   ],
   "source": [
    "print('Installing packages')\n",
    "!pip uninstall -y allennlp torch\n",
    "!pip install /kaggle/input/torch16/torch-1.6.0cu101-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install /kaggle/input/pytorch-image-models/\n",
    "!pip install /kaggle/input/yacs-yet-another-configuration-system/yacs\n",
    "!pip install /kaggle/input/landmark-lib/\n",
    "!pip install /kaggle/input/semantic-segmentation-pytorch/\n",
    "!pip install /kaggle/input/superpoint-pytorch/\n",
    "print('Installed packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:22.086690Z",
     "iopub.status.busy": "2020-09-29T10:34:22.085800Z",
     "iopub.status.idle": "2020-09-29T10:34:26.318700Z",
     "shell.execute_reply": "2020-09-29T10:34:26.318084Z"
    },
    "papermill": {
     "duration": 4.296209,
     "end_time": "2020-09-29T10:34:26.318824",
     "exception": false,
     "start_time": "2020-09-29T10:34:22.022615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir sample\n",
    "!mkdir sample/0\n",
    "!mkdir sample/0/0\n",
    "!mkdir sample/0/0/0\n",
    "!cp /kaggle/input/landmark-recognition-2020/train/0/0/0/* sample/0/0/0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:26.436879Z",
     "iopub.status.busy": "2020-09-29T10:34:26.436007Z",
     "iopub.status.idle": "2020-09-29T10:34:29.163587Z",
     "shell.execute_reply": "2020-09-29T10:34:29.162953Z"
    },
    "papermill": {
     "duration": 2.794612,
     "end_time": "2020-09-29T10:34:29.163741",
     "exception": false,
     "start_time": "2020-09-29T10:34:26.369129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "import os\n",
    "os.environ[\"LRU_CACHE_CAPACITY\"] = \"3\"\n",
    "import gc\n",
    "import operator\n",
    "import pathlib\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import pydegensac\n",
    "from scipy import spatial\n",
    "import torch; print(torch.__version__)\n",
    "torch.set_grad_enabled(False)\n",
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.pytorch import ToTensorV2  \n",
    "from albumentations.augmentations import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:29.271440Z",
     "iopub.status.busy": "2020-09-29T10:34:29.270162Z",
     "iopub.status.idle": "2020-09-29T10:34:29.274210Z",
     "shell.execute_reply": "2020-09-29T10:34:29.273737Z"
    },
    "papermill": {
     "duration": 0.05972,
     "end_time": "2020-09-29T10:34:29.274310",
     "exception": false,
     "start_time": "2020-09-29T10:34:29.214590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:29.381268Z",
     "iopub.status.busy": "2020-09-29T10:34:29.380281Z",
     "iopub.status.idle": "2020-09-29T10:34:29.510288Z",
     "shell.execute_reply": "2020-09-29T10:34:29.509164Z"
    },
    "papermill": {
     "duration": 0.186985,
     "end_time": "2020-09-29T10:34:29.510410",
     "exception": false,
     "start_time": "2020-09-29T10:34:29.323425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/input/landmark-lib/\")\n",
    "sys.path.append('/kaggle/input/superpoint-pytorch/')\n",
    "\n",
    "import cvcore\n",
    "from cvcore.config import get_cfg\n",
    "from cvcore.data.landmark_dataset import thumbnail\n",
    "from cvcore.modeling.meta_arch.landmark_cnn import build_landmark_cls_model \n",
    "from cvcore.modeling.meta_arch.landmark_cnn import GEMPoolCNN, DELG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:29.615888Z",
     "iopub.status.busy": "2020-09-29T10:34:29.614988Z",
     "iopub.status.idle": "2020-09-29T10:34:29.815704Z",
     "shell.execute_reply": "2020-09-29T10:34:29.815124Z"
    },
    "papermill": {
     "duration": 0.255199,
     "end_time": "2020-09-29T10:34:29.815865",
     "exception": false,
     "start_time": "2020-09-29T10:34:29.560666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superpoint_pytorch.models.superpoint import SuperPoint as SP\n",
    "from superpoint_pytorch.models.superglue import SuperGlue as SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:29.920958Z",
     "iopub.status.busy": "2020-09-29T10:34:29.920026Z",
     "iopub.status.idle": "2020-09-29T10:34:29.922443Z",
     "shell.execute_reply": "2020-09-29T10:34:29.923035Z"
    },
    "papermill": {
     "duration": 0.058376,
     "end_time": "2020-09-29T10:34:29.923161",
     "exception": false,
     "start_time": "2020-09-29T10:34:29.864785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_weight(model, weight):\n",
    "    print(f\"=> loading checkpoint {weight}\")\n",
    "    ckpt = torch.load(weight, \"cpu\")\n",
    "\n",
    "    state_dict = ckpt.pop('state_dict')\n",
    "    #print(state_dict.keys())\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.endswith('seesaw_loss.N'):\n",
    "            continue\n",
    "            \n",
    "        new_k = k\n",
    "        if new_k.startswith('module.'):\n",
    "            new_k = new_k[7:]\n",
    "        new_state_dict[new_k.replace(\"se_module\", \"se\")] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print('=> loaded state dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:30.030876Z",
     "iopub.status.busy": "2020-09-29T10:34:30.029875Z",
     "iopub.status.idle": "2020-09-29T10:34:30.033058Z",
     "shell.execute_reply": "2020-09-29T10:34:30.032417Z"
    },
    "papermill": {
     "duration": 0.06037,
     "end_time": "2020-09-29T10:34:30.033176",
     "exception": false,
     "start_time": "2020-09-29T10:34:29.972806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset parameters:\n",
    "INPUT_DIR = os.path.join('..', 'input')\n",
    "\n",
    "DATASET_DIR = os.path.join(INPUT_DIR, 'landmark-recognition-2020')\n",
    "TEST_IMAGE_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "TRAIN_IMAGE_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "TRAIN_LABELMAP_PATH = os.path.join(DATASET_DIR, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:30.154019Z",
     "iopub.status.busy": "2020-09-29T10:34:30.152972Z",
     "iopub.status.idle": "2020-09-29T10:34:30.155954Z",
     "shell.execute_reply": "2020-09-29T10:34:30.155338Z"
    },
    "papermill": {
     "duration": 0.073527,
     "end_time": "2020-09-29T10:34:30.156093",
     "exception": false,
     "start_time": "2020-09-29T10:34:30.082566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEBUGGING PARAMS:\n",
    "NUM_PUBLIC_TRAIN_IMAGES = 1580470 # Used to detect if in session or re-run.\n",
    "MAX_NUM_EMBEDDINGS = -1  # Set to > 1 to subsample dataset while debugging. # TODO:\n",
    "\n",
    "# Retrieval & re-ranking parameters:\n",
    "NUM_TO_RERANK = 5\n",
    "TOP_K = 3 # Number of retrieved images used to make prediction for a test image.\n",
    "\n",
    "# RANSAC parameters:\n",
    "# MAX_INLIER_SCORE = 50 # public LB: 0.5548\n",
    "# MAX_INLIER_SCORE = 60 # public LB: 0.5591\n",
    "MAX_INLIER_SCORE = 200\n",
    "MAX_REPROJECTION_ERROR = 4.0\n",
    "MAX_RANSAC_ITERATIONS = 1000\n",
    "HOMOGRAPHY_CONFIDENCE = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:30.264245Z",
     "iopub.status.busy": "2020-09-29T10:34:30.263375Z",
     "iopub.status.idle": "2020-09-29T10:34:30.267396Z",
     "shell.execute_reply": "2020-09-29T10:34:30.266841Z"
    },
    "papermill": {
     "duration": 0.061011,
     "end_time": "2020-09-29T10:34:30.267545",
     "exception": false,
     "start_time": "2020-09-29T10:34:30.206534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DELF Config\n",
    "stride_factor = 1 # 2\n",
    "rf, stride, padding = [291.0, 16.0 * stride_factor, 145.0]\n",
    "feature_depth = 128 # nhannt: 128, delf: 1024\n",
    "scales = (1,) # 1 / math.sqrt(2), 1, math.sqrt(2)\n",
    "ABS_THRESHOLD = 175 # How to choose this number\n",
    "LOCAL_FEATURE_NUM_TENSOR = 1000\n",
    "NMS_IOU = 1.\n",
    "\n",
    "# Global feature extraction:\n",
    "NUM_EMBEDDING_DIMENSIONS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:30.371349Z",
     "iopub.status.busy": "2020-09-29T10:34:30.370691Z",
     "iopub.status.idle": "2020-09-29T10:34:30.374396Z",
     "shell.execute_reply": "2020-09-29T10:34:30.375193Z"
    },
    "papermill": {
     "duration": 0.05893,
     "end_time": "2020-09-29T10:34:30.375356",
     "exception": false,
     "start_time": "2020-09-29T10:34:30.316426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation\n",
    "aug = Compose([\n",
    "    Normalize(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048715,
     "end_time": "2020-09-29T10:34:30.473246",
     "exception": false,
     "start_time": "2020-09-29T10:34:30.424531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Global features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:30.586716Z",
     "iopub.status.busy": "2020-09-29T10:34:30.585790Z",
     "iopub.status.idle": "2020-09-29T10:34:48.980254Z",
     "shell.execute_reply": "2020-09-29T10:34:48.979089Z"
    },
    "papermill": {
     "duration": 18.458179,
     "end_time": "2020-09-29T10:34:48.980397",
     "exception": false,
     "start_time": "2020-09-29T10:34:30.522218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint /kaggle/input/best-resnext101-32x4d-cluster/best_resnext101_32x4d_clusterv2.pth\n",
      "=> loaded state dict\n",
      "=> loading checkpoint /kaggle/input/best-seresnet101-cluster/best_seresnet101_clusterv2.pth\n",
      "=> loaded state dict\n",
      "WARNING: 'drop_connect' as an argument is deprecated, please use 'drop_path'. Setting drop_path to 0.200000.\n",
      "=> loading checkpoint /kaggle/input/effnetb6/best_b6_clusterv2.pth\n",
      "=> loaded state dict\n",
      "=> loading checkpoint /kaggle/input/res101/best_resnet101_clusterv2.pth\n",
      "=> loaded state dict\n"
     ]
    }
   ],
   "source": [
    "def get_model(config_path, weight_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_path)\n",
    "    cfg.MODEL.BACKBONE.PRETRAINED = False # avoid download imagenet weight\n",
    "    INTERP = cfg.DATA.INTERP # match training interpolation\n",
    "\n",
    "\n",
    "    class GEMPoolExtractor(GEMPoolCNN):\n",
    "\n",
    "        def __init__(self, cfg):\n",
    "            super(GEMPoolExtractor, self).__init__(cfg)\n",
    "\n",
    "        def forward(self, images):\n",
    "            with autocast():\n",
    "                features = self.backbone(images)\n",
    "                features = [features[f] for f in self.in_features]\n",
    "                _, global_features = features\n",
    "                global_features = self.pool(global_features)\n",
    "                return global_features\n",
    "\n",
    "    model = GEMPoolExtractor(cfg)\n",
    "    load_weight(model, weight_path)\n",
    "    del model.cls_head; gc.collect()\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    return model, INTERP\n",
    "\n",
    "\n",
    "model1, INTERP = get_model('/kaggle/input/landmark-lib/configs/google-landmark/resnext101_32x4d.yaml', \n",
    "                           '/kaggle/input/best-resnext101-32x4d-cluster/best_resnext101_32x4d_clusterv2.pth')\n",
    "\n",
    "model2, INTERP = get_model('/kaggle/input/best-seresnet101-cluster/seresnet101.yaml', \n",
    "                           '/kaggle/input/best-seresnet101-cluster/best_seresnet101_clusterv2.pth')\n",
    "\n",
    "model3, INTERP = get_model('/kaggle/input/effnetb6/b6.yaml',\n",
    "                           '/kaggle/input/effnetb6/best_b6_clusterv2.pth')\n",
    "\n",
    "model4, INTERP = get_model('/kaggle/input/res101/resnet101.yaml',\n",
    "                           '/kaggle/input/res101/best_resnet101_clusterv2.pth')\n",
    "\n",
    "\n",
    "MODELS = [model1, model2, model3, model4]\n",
    "MODEL_NAMES = ['resnext101_clusterv2', 'seresnet101_clusterv2', 'b6_clusterv2', 'resnet101_clusterv2']\n",
    "# MODEL_WEIGHTS = [2.0, 1.5, 0.75, 0.75]\n",
    "MODEL_WEIGHTS = [2.0, 1.0, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:49.112013Z",
     "iopub.status.busy": "2020-09-29T10:34:49.109975Z",
     "iopub.status.idle": "2020-09-29T10:34:49.112897Z",
     "shell.execute_reply": "2020-09-29T10:34:49.113437Z"
    },
    "papermill": {
     "duration": 0.077523,
     "end_time": "2020-09-29T10:34:49.113595",
     "exception": false,
     "start_time": "2020-09-29T10:34:49.036072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def extract_global_features(image_root_dir, pre_compute=False):\n",
    "    image_paths = [x for x in pathlib.Path(image_root_dir).rglob('*.jpg')]\n",
    "        \n",
    "    num_embeddings = len(image_paths)\n",
    "    print(\"Num images: \", num_embeddings)\n",
    "    \n",
    "    if MAX_NUM_EMBEDDINGS > 0:\n",
    "        num_embeddings = min(MAX_NUM_EMBEDDINGS, num_embeddings)\n",
    "\n",
    "    ids = num_embeddings * [None]\n",
    "    embeddings = np.empty((len(MODELS), num_embeddings, NUM_EMBEDDING_DIMENSIONS))\n",
    "\n",
    "    if pre_compute:\n",
    "        # Loop through all model names\n",
    "        for m, name in enumerate(MODEL_NAMES):\n",
    "            emb_dict = torch.load(f\"/kaggle/input/train-embeddings/{name}.pth\", \"cpu\")\n",
    "            for i, image_path in tqdm(enumerate(image_paths), total=num_embeddings):\n",
    "                image_id = image_path.stem\n",
    "                if image_id in emb_dict.keys():\n",
    "                    ids[i] = int(image_path.name.split('.')[0], 16)\n",
    "                    embeddings[m, i, :] = emb_dict[image_id].squeeze(0).numpy()\n",
    "            del emb_dict; gc.collect()\n",
    "        \n",
    "    for i, image_path in tqdm(enumerate(image_paths), total=num_embeddings):\n",
    "        if i >= num_embeddings:\n",
    "            break\n",
    "        if ids[i] != None:\n",
    "            continue\n",
    "\n",
    "        ids[i] = int(image_path.name.split('.')[0], 16)\n",
    "\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "        # Resize longer edge to max 1024\n",
    "        image = thumbnail(image)\n",
    "        image = aug(image=image)['image']\n",
    "        # Add bs dimension\n",
    "        image.unsqueeze_(0)\n",
    "        image = image.cuda(non_blocking=True)\n",
    "    \n",
    "        for m in range(len(MODELS)):\n",
    "            global_descriptors = MODELS[m](image)\n",
    "            embeddings[m, i, :] = F.normalize(global_descriptors.sum(dim=0), dim=0).cpu().numpy()\n",
    "            \n",
    "    return ids, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:49.228463Z",
     "iopub.status.busy": "2020-09-29T10:34:49.227709Z",
     "iopub.status.idle": "2020-09-29T10:34:49.231586Z",
     "shell.execute_reply": "2020-09-29T10:34:49.230947Z"
    },
    "papermill": {
     "duration": 0.06363,
     "end_time": "2020-09-29T10:34:49.231743",
     "exception": false,
     "start_time": "2020-09-29T10:34:49.168113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_hex(image_id):\n",
    "    return '{0:0{1}x}'.format(image_id, 16)\n",
    "\n",
    "\n",
    "def get_image_path(data_dir, image_id):\n",
    "    name = to_hex(image_id)\n",
    "    return os.path.join(data_dir, name[0], name[1], name[2],\n",
    "                      '{}.jpg'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:49.345969Z",
     "iopub.status.busy": "2020-09-29T10:34:49.344049Z",
     "iopub.status.idle": "2020-09-29T10:34:49.346688Z",
     "shell.execute_reply": "2020-09-29T10:34:49.347221Z"
    },
    "papermill": {
     "duration": 0.062657,
     "end_time": "2020-09-29T10:34:49.347364",
     "exception": false,
     "start_time": "2020-09-29T10:34:49.284707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_total_score(num_inliers, global_score):\n",
    "    local_score = min(num_inliers + 1, MAX_INLIER_SCORE) / MAX_INLIER_SCORE\n",
    "    return local_score * global_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053777,
     "end_time": "2020-09-29T10:34:49.455577",
     "exception": false,
     "start_time": "2020-09-29T10:34:49.401800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SuperPoint + SuperGlue for local re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:49.572012Z",
     "iopub.status.busy": "2020-09-29T10:34:49.570910Z",
     "iopub.status.idle": "2020-09-29T10:34:51.362891Z",
     "shell.execute_reply": "2020-09-29T10:34:51.362048Z"
    },
    "papermill": {
     "duration": 1.852904,
     "end_time": "2020-09-29T10:34:51.363028",
     "exception": false,
     "start_time": "2020-09-29T10:34:49.510124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loading weights for net_encoder\n",
      "Loading weights for net_decoder\n",
      "Loaded ADE20k segmentation model\n",
      "Loaded SuperGlue model (\"outdoor\" weights)\n",
      "Finished loading SuperPoint + SuperGlue\n"
     ]
    }
   ],
   "source": [
    "local_extractor = SP({\n",
    "  'keypoint_threshold': 0.001, \n",
    "  'max_keypoints': 2048,\n",
    "  \"seg_backbone\": \"hrnetv2\",\n",
    "  'seg_mask': True,\n",
    "  'homographic': False,\n",
    "})\n",
    "local_matcher = SG({'match_threshold': 0.2, 'weights': 'outdoor', 'sinkhorn_iterations': 150})\n",
    "\n",
    "local_extractor.eval()\n",
    "local_matcher.eval()\n",
    "local_extractor = local_extractor.cuda()\n",
    "local_matcher = local_matcher.cuda()\n",
    "print('Finished loading SuperPoint + SuperGlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:51.480296Z",
     "iopub.status.busy": "2020-09-29T10:34:51.478226Z",
     "iopub.status.idle": "2020-09-29T10:34:51.480998Z",
     "shell.execute_reply": "2020-09-29T10:34:51.481499Z"
    },
    "papermill": {
     "duration": 0.063358,
     "end_time": "2020-09-29T10:34:51.481648",
     "exception": false,
     "start_time": "2020-09-29T10:34:51.418290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed(42)\n",
    "# PERCENT_FILTER = 0.3\n",
    "\n",
    "# def extract_superpoint_features(image_path,\n",
    "#                                 local_extractor=local_extractor,\n",
    "#                                 filter_keypoints=False):\n",
    "#     image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "#     image = image.astype(np.float32)\n",
    "#     image = thumbnail(image, max_size=640)\n",
    "#     image = image / 255.\n",
    "#     image = torch.from_numpy(image).permute(2, 0, 1)[None].float()\n",
    "#     image = image.cuda(non_blocking=True)\n",
    "    \n",
    "#     # Whether to remove keypoints from various semantic masks\n",
    "#     if filter_keypoints and random.uniform(0, 1) < PERCENT_FILTER:\n",
    "#         local_extractor.seg_mask = filter_keypoints\n",
    "#     pred = local_extractor({'image': image})\n",
    "#     pred = {k: torch.stack(v) for k, v in pred.items()}\n",
    "#     pred['image_shape'] = image.shape[-2:]\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:51.599499Z",
     "iopub.status.busy": "2020-09-29T10:34:51.597676Z",
     "iopub.status.idle": "2020-09-29T10:34:51.600200Z",
     "shell.execute_reply": "2020-09-29T10:34:51.600691Z"
    },
    "papermill": {
     "duration": 0.064561,
     "end_time": "2020-09-29T10:34:51.600810",
     "exception": false,
     "start_time": "2020-09-29T10:34:51.536249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_num_inliers_superglue(data, local_matcher=local_matcher):\n",
    "    scores = local_matcher(data)['matching_scores0']    \n",
    "    num_inliers = torch.clamp(scores, 0.0, 1.0).sum().item()\n",
    "    return num_inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:51.729840Z",
     "iopub.status.busy": "2020-09-29T10:34:51.727903Z",
     "iopub.status.idle": "2020-09-29T10:34:51.730587Z",
     "shell.execute_reply": "2020-09-29T10:34:51.731169Z"
    },
    "papermill": {
     "duration": 0.075809,
     "end_time": "2020-09-29T10:34:51.731308",
     "exception": false,
     "start_time": "2020-09-29T10:34:51.655499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 896, 672\n",
    "\n",
    "def rescore_and_rerank_by_num_inliers(test_image_id,\n",
    "                                      train_ids_labels_and_scores):\n",
    "    \"\"\"Returns rescored and sorted training images by local feature extraction.\"\"\"\n",
    "    \n",
    "    def load_image(image_path):\n",
    "        image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "        image = functional.resize(image, height=HEIGHT, width=WIDTH, interpolation=cv2.INTER_LINEAR)\n",
    "        image = image.astype(np.float32) / 255.\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "        return image\n",
    "    \n",
    "    image_paths = []\n",
    "    image_paths.append(get_image_path(TEST_IMAGE_DIR, test_image_id))\n",
    "    for i in range(len(train_ids_labels_and_scores)):\n",
    "        train_image_id, _, _ = train_ids_labels_and_scores[i]\n",
    "        image_paths.append(get_image_path(TRAIN_IMAGE_DIR, train_image_id))\n",
    "    images = torch.stack([load_image(p) for p in image_paths], 0)\n",
    "    images = images.cuda(non_blocking=True)\n",
    "    \n",
    "    outputs = local_extractor({\"image\": images})\n",
    "    data = {}\n",
    "    for k, v in outputs.items():\n",
    "        data[k+'0'] = v[0][None]\n",
    "    data['image_shape0'] = data['image_shape1'] = [HEIGHT, WIDTH]\n",
    "    \n",
    "    for i in range(len(train_ids_labels_and_scores)):\n",
    "        train_image_id, label, global_score = train_ids_labels_and_scores[i]\n",
    "        for k, v in outputs.items():\n",
    "            data[k+'1'] = v[i+1][None]\n",
    "            \n",
    "        num_inliers = get_num_inliers_superglue(data)  \n",
    "#         print(\"=\"*100)\n",
    "#         print(f\"Test {test_image_id} - train {train_image_id} - inliers {num_inliers}\")\n",
    "        total_score = get_total_score(num_inliers, global_score)\n",
    "        train_ids_labels_and_scores[i] = (train_image_id, label, total_score)\n",
    "    train_ids_labels_and_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return train_ids_labels_and_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:51.858220Z",
     "iopub.status.busy": "2020-09-29T10:34:51.857367Z",
     "iopub.status.idle": "2020-09-29T10:34:51.861534Z",
     "shell.execute_reply": "2020-09-29T10:34:51.860976Z"
    },
    "papermill": {
     "duration": 0.072237,
     "end_time": "2020-09-29T10:34:51.861640",
     "exception": false,
     "start_time": "2020-09-29T10:34:51.789403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labelmap():\n",
    "    with open(TRAIN_LABELMAP_PATH, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        labelmap = {row['id']: row['landmark_id'] for row in csv_reader}\n",
    "\n",
    "    return labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:51.981023Z",
     "iopub.status.busy": "2020-09-29T10:34:51.980255Z",
     "iopub.status.idle": "2020-09-29T10:34:51.984441Z",
     "shell.execute_reply": "2020-09-29T10:34:51.983925Z"
    },
    "papermill": {
     "duration": 0.067929,
     "end_time": "2020-09-29T10:34:51.984558",
     "exception": false,
     "start_time": "2020-09-29T10:34:51.916629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prediction_map(test_ids, train_ids_labels_and_scores):\n",
    "    \"\"\"Makes dict from test ids and ranked training ids, labels, scores.\"\"\"\n",
    "\n",
    "    prediction_map = dict()\n",
    "\n",
    "    for test_index, test_id in enumerate(test_ids):\n",
    "        hex_test_id = to_hex(test_id)\n",
    "\n",
    "        aggregate_scores = {}\n",
    "        for _, label, score in train_ids_labels_and_scores[test_index][:TOP_K]:\n",
    "            aggregate_scores[label] = aggregate_scores.get(label, 0) + score\n",
    "\n",
    "        label, score = max(aggregate_scores.items(), key=operator.itemgetter(1))\n",
    "\n",
    "        prediction_map[hex_test_id] = {'score': score, 'class': label}\n",
    "\n",
    "    return prediction_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:52.112317Z",
     "iopub.status.busy": "2020-09-29T10:34:52.111216Z",
     "iopub.status.idle": "2020-09-29T10:34:52.114598Z",
     "shell.execute_reply": "2020-09-29T10:34:52.114001Z"
    },
    "papermill": {
     "duration": 0.073915,
     "end_time": "2020-09-29T10:34:52.114708",
     "exception": false,
     "start_time": "2020-09-29T10:34:52.040793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(labelmap):\n",
    "    \"\"\"Gets predictions using embedding similarity and local feature reranking.\"\"\"\n",
    "\n",
    "    test_ids, test_embeddings = extract_global_features(TEST_IMAGE_DIR)\n",
    "    train_ids, train_embeddings = extract_global_features(TRAIN_IMAGE_DIR, pre_compute=True)\n",
    "\n",
    "    train_ids_labels_and_scores = [None] * test_embeddings.shape[1]\n",
    "\n",
    "    # Using (slow) for-loop, as distance matrix doesn't fit in memory.\n",
    "    for test_index in range(test_embeddings.shape[1]):\n",
    "        similarities = np.ones(train_embeddings.shape[1], dtype=np.float32)\n",
    "        for m in range(test_embeddings.shape[0]):\n",
    "            similarities *= (np.clip(0.8 - spatial.distance.cdist(test_embeddings[np.newaxis, m, test_index, :], \n",
    "                                                                  train_embeddings[m], 'cosine')[0], 0.1, None)/0.8)**(MODEL_WEIGHTS[m]/sum(MODEL_WEIGHTS))\n",
    "        distances = 1 - similarities\n",
    "        partition = np.argpartition(distances, NUM_TO_RERANK)[:NUM_TO_RERANK]\n",
    "\n",
    "        nearest = sorted([(train_ids[p], distances[p]) for p in partition],\n",
    "                         key=lambda x: x[1])\n",
    "\n",
    "        train_ids_labels_and_scores[test_index] = [\n",
    "            (train_id, labelmap[to_hex(train_id)], 1. - cosine_distance)\n",
    "            for train_id, cosine_distance in nearest\n",
    "        ]\n",
    "\n",
    "    del test_embeddings\n",
    "    del train_embeddings\n",
    "    del labelmap\n",
    "    gc.collect()\n",
    "\n",
    "    pre_verification_predictions = get_prediction_map(\n",
    "      test_ids, train_ids_labels_and_scores)\n",
    "\n",
    "\n",
    "    for test_index, test_id in enumerate(test_ids):\n",
    "        train_ids_labels_and_scores[test_index] = rescore_and_rerank_by_num_inliers(\n",
    "            test_id, train_ids_labels_and_scores[test_index])\n",
    "\n",
    "    post_verification_predictions = get_prediction_map(\n",
    "      test_ids, train_ids_labels_and_scores)\n",
    "\n",
    "    return pre_verification_predictions, post_verification_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:52.240910Z",
     "iopub.status.busy": "2020-09-29T10:34:52.238775Z",
     "iopub.status.idle": "2020-09-29T10:34:52.241724Z",
     "shell.execute_reply": "2020-09-29T10:34:52.242273Z"
    },
    "papermill": {
     "duration": 0.069184,
     "end_time": "2020-09-29T10:34:52.242399",
     "exception": false,
     "start_time": "2020-09-29T10:34:52.173215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_submission_csv(predictions=None):\n",
    "    \"\"\"Saves optional `predictions` as submission.csv.\n",
    "\n",
    "    The csv has columns {id, landmarks}. The landmarks column is a string\n",
    "    containing the label and score for the id, separated by a ws delimeter.\n",
    "\n",
    "    If `predictions` is `None` (default), submission.csv is copied from\n",
    "    sample_submission.csv in `IMAGE_DIR`.\n",
    "\n",
    "    Args:\n",
    "    predictions: Optional dict of image ids to dicts with keys {class, score}.\n",
    "    \"\"\"\n",
    "\n",
    "    if predictions is None:\n",
    "        # Dummy submission!\n",
    "        shutil.copyfile(\n",
    "            os.path.join(DATASET_DIR, 'sample_submission.csv'), 'submission.csv')\n",
    "        return\n",
    "\n",
    "    with open('submission.csv', 'w') as submission_csv:\n",
    "        csv_writer = csv.DictWriter(submission_csv, fieldnames=['id', 'landmarks'])\n",
    "        csv_writer.writeheader()\n",
    "        for image_id, prediction in predictions.items():\n",
    "            label = prediction['class']\n",
    "            score = prediction['score']\n",
    "            csv_writer.writerow({'id': image_id, 'landmarks': f'{label} {score}'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:34:52.362005Z",
     "iopub.status.busy": "2020-09-29T10:34:52.361130Z",
     "iopub.status.idle": "2020-09-29T10:56:33.613254Z",
     "shell.execute_reply": "2020-09-29T10:56:33.611825Z"
    },
    "papermill": {
     "duration": 1301.31565,
     "end_time": "2020-09-29T10:56:33.613427",
     "exception": false,
     "start_time": "2020-09-29T10:34:52.297777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/407 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1580470 training images.\n",
      "Num images:  407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [01:27<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images:  407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:00<00:00, 16647.47it/s]\n",
      "100%|██████████| 407/407 [00:00<00:00, 42656.78it/s]\n",
      "100%|██████████| 407/407 [00:00<00:00, 31192.68it/s]\n",
      "100%|██████████| 407/407 [00:00<00:00, 37020.34it/s]\n",
      "100%|██████████| 407/407 [00:00<00:00, 375182.80it/s]\n",
      "/kaggle/input/superpoint-pytorch/superpoint_pytorch/models/superpoint.py:298: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  keypoints = [torch.nonzero(s > self.config[\"keypoint_threshold\"]) for s in scores]\n"
     ]
    }
   ],
   "source": [
    "def subsample(x, n=32):\n",
    "    out = dict()\n",
    "    for k in list(x.keys())[:n]:\n",
    "        out[k] = x[k]\n",
    "    return out\n",
    "\n",
    "\n",
    "labelmap = load_labelmap()\n",
    "num_training_images = len(labelmap.keys())\n",
    "print(f'Found {num_training_images} training images.')\n",
    "if num_training_images == NUM_PUBLIC_TRAIN_IMAGES:\n",
    "    TEST_IMAGE_DIR = \"sample\"\n",
    "    TRAIN_IMAGE_DIR = \"sample\"\n",
    "\n",
    "_, post_verification_predictions = get_predictions(labelmap)\n",
    "\n",
    "if num_training_images == NUM_PUBLIC_TRAIN_IMAGES:\n",
    "    save_submission_csv()\n",
    "else:\n",
    "    save_submission_csv(post_verification_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-29T10:56:34.062649Z",
     "iopub.status.busy": "2020-09-29T10:56:34.061807Z",
     "iopub.status.idle": "2020-09-29T10:56:34.066309Z",
     "shell.execute_reply": "2020-09-29T10:56:34.066850Z"
    },
    "papermill": {
     "duration": 0.234803,
     "end_time": "2020-09-29T10:56:34.066981",
     "exception": false,
     "start_time": "2020-09-29T10:56:33.832178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000a350223f0d81e': {'score': 0.9682963490486145, 'class': '55450'},\n",
       " '0006e8d7218033ff': {'score': 0.9779824614524841, 'class': '76284'},\n",
       " '000234836dba6876': {'score': 0.9617262482643127, 'class': '194039'},\n",
       " '000b355c94ff99e8': {'score': 0.9303506016731262, 'class': '42935'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample(post_verification_predictions, n=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1564.519213,
   "end_time": "2020-09-29T10:56:35.500699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-29T10:30:30.981486",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
